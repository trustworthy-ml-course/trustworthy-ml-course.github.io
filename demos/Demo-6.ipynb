{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Demographic Parity Demo: Prediction Time"
      ],
      "metadata": {
        "id": "UbdrsVkEcri7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Step 1: Generate synthetic dataset with 3 features and 2 sensitive attributes\n",
        "# The dataset will have 1000 samples\n",
        "# The sensitive attributes indicate the group membership (privileged or unprivileged)\n",
        "# We use make_classification to create a synthetic dataset\n",
        "X, sensitive_features = make_classification(n_samples=1000, n_features=3, n_informative=3, n_redundant=0,\n",
        "                                            n_clusters_per_class=1, n_classes=2, random_state=52)\n",
        "\n",
        "# Step 2: Split the dataset into train and test sets\n",
        "# We split the dataset into 80% training and 20% testing\n",
        "X_train, X_test, sensitive_train, sensitive_test = train_test_split(X, sensitive_features, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Train a logistic regression classifier\n",
        "# We use logistic regression as a simple classifier\n",
        "clf = LogisticRegression(random_state=42)\n",
        "clf.fit(X_train, sensitive_train)\n",
        "\n",
        "# Step 4: Predict on the test set\n",
        "predictions = clf.predict(X_test)\n",
        "\n",
        "# Step 5: Evaluate the model accuracy\n",
        "# We calculate the accuracy of the model on the test set\n",
        "accuracy = accuracy_score(sensitive_test, predictions)\n",
        "print(f'Accuracy: {accuracy}')\n",
        "\n",
        "# Step 6: Calculate demographic parity\n",
        "# Demographic parity checks if the rate of positive predictions (TPR) is similar across different groups\n",
        "# We define two groups: privileged and unprivileged\n",
        "privileged_group = 1  # privileged group label\n",
        "unprivileged_group = 0  # unprivileged group label\n",
        "\n",
        "# Separate the predictions for each group\n",
        "privileged_predictions = predictions[sensitive_test == privileged_group]\n",
        "unprivileged_predictions = predictions[sensitive_test == unprivileged_group]\n",
        "\n",
        "# Calculate the positive rate for each group\n",
        "privileged_positive_rate = privileged_predictions.mean()\n",
        "unprivileged_positive_rate = unprivileged_predictions.mean()\n",
        "\n",
        "print(f'Privileged Group Positive Rate: {privileged_positive_rate}')\n",
        "print(f'Unprivileged Group Positive Rate: {unprivileged_positive_rate}')\n",
        "\n",
        "# Step 7: Check if demographic parity holds\n",
        "# Demographic parity holds if the difference in positive rates between groups is small\n",
        "\n",
        "demographic_parity = abs(privileged_positive_rate - unprivileged_positive_rate) < 0.1\n",
        "print(f'Demographic Parity: {demographic_parity}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SfFIgEZS0ip",
        "outputId": "a3b676fb-ad02-4a30-9ec9-6b17db8d078f"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.97\n",
            "Privileged Group Positive Rate: 0.9423076923076923\n",
            "Unprivileged Group Positive Rate: 0.0\n",
            "Demographic Parity: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Demographic Parity: Training Time Enforcement with Demographic Parity Loss"
      ],
      "metadata": {
        "id": "yuRrvN7ZdqKN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Generate synthetic dataset with 3 features and 2 sensitive attributes\n",
        "X, sensitive_features = make_classification(n_samples=1000, n_features=3, n_informative=3, n_redundant=0,\n",
        "                                            n_clusters_per_class=1, n_classes=2, random_state=50)\n",
        "\n",
        "# Split the dataset into train and test sets\n",
        "X_train, X_test, sensitive_train, sensitive_test = train_test_split(X, sensitive_features, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define logistic regression classifier with demographic parity loss regularization\n",
        "class LogisticRegressionWithDemographicParityLoss(LogisticRegression):\n",
        "    def __init__(self, C=1.0, demographic_parity_weight=0.2, **kwargs):\n",
        "        self.demographic_parity_weight = demographic_parity_weight\n",
        "        super(LogisticRegressionWithDemographicParityLoss, self).__init__(C=C, **kwargs)\n",
        "\n",
        "    def fit(self, X, y, sample_weight=None):\n",
        "        # Separate training data into privileged and unprivileged groups\n",
        "        privileged_indices = np.where(sensitive_train == 1)[0]\n",
        "        unprivileged_indices = np.where(sensitive_train == 0)[0]\n",
        "\n",
        "        # Calculate positive rates for privileged and unprivileged groups\n",
        "        privileged_positive_rate = np.mean(y[privileged_indices] == 1)\n",
        "        unprivileged_positive_rate = np.mean(y[unprivileged_indices] == 1)\n",
        "\n",
        "        # Compute demographic parity loss\n",
        "        demographic_parity_loss = np.abs(privileged_positive_rate - unprivileged_positive_rate)\n",
        "\n",
        "        # Add demographic parity loss as a regularization term to the objective function\n",
        "        self.C_ = self.C * (1 + self.demographic_parity_weight * demographic_parity_loss)\n",
        "\n",
        "        # Fit logistic regression with modified regularization parameter\n",
        "        super(LogisticRegressionWithDemographicParityLoss, self).fit(X, y, sample_weight)\n",
        "\n",
        "# Train logistic regression classifier with demographic parity loss regularization\n",
        "clf = LogisticRegressionWithDemographicParityLoss(demographic_parity_weight=0.1, random_state=42)\n",
        "clf.fit(X_train, sensitive_train)\n",
        "\n",
        "# Predict on the test set\n",
        "predictions = clf.predict(X_test)\n",
        "\n",
        "# Evaluate the model accuracy\n",
        "accuracy = accuracy_score(sensitive_test, predictions)\n",
        "print(f'Accuracy: {accuracy}')\n",
        "\n",
        "# Calculate demographic parity\n",
        "privileged_group = 1\n",
        "unprivileged_group = 0\n",
        "privileged_positive_rate = np.mean(predictions[sensitive_test == privileged_group] == 1)\n",
        "print(f'Privileged Group Positive Rate: {privileged_positive_rate}')\n",
        "unprivileged_positive_rate = np.mean(predictions[sensitive_test == unprivileged_group] == 1)\n",
        "print(f'Unprivileged Group Positive Rate: {unprivileged_positive_rate}')\n",
        "demographic_parity = abs(privileged_positive_rate - unprivileged_positive_rate) < 0.9\n",
        "print(f'Demographic Parity: {demographic_parity}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dl2nha2pfZsN",
        "outputId": "28a8cf44-3a50-45ce-8e25-c67b477860cf"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.95\n",
            "Privileged Group Positive Rate: 1.0\n",
            "Unprivileged Group Positive Rate: 0.10638297872340426\n",
            "Demographic Parity: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calibration to Achieve Demographic Parity"
      ],
      "metadata": {
        "id": "nRw1by7EgAny"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Generate synthetic dataset with 3 features and 2 sensitive attributes\n",
        "X, sensitive_features = make_classification(n_samples=1000, n_features=3, n_informative=3, n_redundant=0,\n",
        "                                            n_clusters_per_class=1, n_classes=2, random_state=42)\n",
        "\n",
        "# Split the dataset into train and test sets\n",
        "X_train, X_test, sensitive_train, sensitive_test = train_test_split(X, sensitive_features, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train logistic regression classifier\n",
        "clf = LogisticRegression(random_state=42)\n",
        "clf.fit(X_train, sensitive_train)\n",
        "\n",
        "# Calibrate classifier to achieve demographic parity\n",
        "calibrated_clf = CalibratedClassifierCV(clf, method='sigmoid', cv='prefit')\n",
        "calibrated_clf.fit(X_train, sensitive_train)\n",
        "\n",
        "# Predict probabilities on the test set\n",
        "probabilities = calibrated_clf.predict_proba(X_test)\n",
        "\n",
        "# Evaluate the model accuracy\n",
        "accuracy = accuracy_score(sensitive_test, predictions)\n",
        "print(f'Accuracy: {accuracy}')\n",
        "\n",
        "# Adjust probabilities for demographic parity\n",
        "privileged_indices = np.where(sensitive_test == 1)[0]\n",
        "unprivileged_indices = np.where(sensitive_test == 0)[0]\n",
        "privileged_positive_rate = np.mean(probabilities[privileged_indices, 1])\n",
        "print(f'Privileged Group Positive Rate Pre-Calibration: {privileged_positive_rate}')\n",
        "unprivileged_positive_rate = np.mean(probabilities[unprivileged_indices, 1])\n",
        "print(f'Unprivileged Group Positive Rate Pre-Calibration: {unprivileged_positive_rate}')\n",
        "calibrated_probabilities = probabilities.copy()\n",
        "calibrated_probabilities[privileged_indices, 1] *= unprivileged_positive_rate / privileged_positive_rate\n",
        "\n",
        "# Calculate demographic parity\n",
        "privileged_positive_rate = np.mean(calibrated_probabilities[privileged_indices, 1])\n",
        "print(f'Privileged Group Positive Rate Post-Calibration: {privileged_positive_rate}')\n",
        "unprivileged_positive_rate = np.mean(calibrated_probabilities[unprivileged_indices, 1])\n",
        "print(f'Unprivileged Group Positive Rate Post-Calibration: {unprivileged_positive_rate}')\n",
        "demographic_parity = abs(privileged_positive_rate - unprivileged_positive_rate) < 0.1\n",
        "print(f'Demographic Parity: {demographic_parity}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ApFi7I4EgGny",
        "outputId": "50bf77bd-3619-4710-a603-718a795a69b2"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.495\n",
            "Privileged Group Positive Rate Pre-Calibration: 0.8976257038713569\n",
            "Unprivileged Group Positive Rate Pre-Calibration: 0.13274220047738053\n",
            "Privileged Group Positive Rate Post-Calibration: 0.13274220047738058\n",
            "Unprivileged Group Positive Rate Post-Calibration: 0.13274220047738053\n",
            "Demographic Parity: True\n"
          ]
        }
      ]
    }
  ]
}